{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def create_dict_from_xml(chemin_fichier):\n",
    "    with open(chemin_fichier, encoding='utf8') as fd:\n",
    "        doc = xmltodict.parse(fd.read(), dict_constructor=dict)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Parse le dictionnaire des types complexes et retourne le résultat dans un dataframe et un dictionnaire\n",
    "\"\"\"\n",
    "\n",
    "def _parse_complex_type(annexe_type : dict):\n",
    "    list_records = []\n",
    "    all_complex_type = annexe_type['xs:schema']['xs:complexType']\n",
    "    i=0\n",
    "    for complex_type in all_complex_type:\n",
    "        temp_dict = dict()\n",
    "        nom_type_complexe = complex_type['@name']\n",
    "        if isinstance(complex_type['xs:attribute'], dict):\n",
    "            for element in complex_type['xs:attribute']['xs:simpleType']['xs:restriction']['xs:enumeration']:\n",
    "                temp_dict[element['@value']] = element.get('xs:annotation', {}).get('xs:documentation', element['@value'])\n",
    "        \n",
    "        result_dict = {\n",
    "            \"type\" : nom_type_complexe,\n",
    "            \"enum\" : temp_dict\n",
    "        }\n",
    "        list_records.append(result_dict)\n",
    "    \n",
    "    df = pd.DataFrame.from_records(list_records)\n",
    "\n",
    "    return df\n",
    "\n",
    "def _generate_complex_type_df(chemin : Path) -> pd.DataFrame:\n",
    "    annexe_type = create_dict_from_xml(chemin)\n",
    "    complexe_types_df = _parse_complex_type(annexe_type)\n",
    "    \n",
    "    return complexe_types_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Génération d'une documentation des codes de données des annexes\n",
    "\"\"\"\n",
    "\n",
    "def _parse_annexe_fields_documentation(class_annexe : dict) -> pd.DataFrame:\n",
    "    elements = class_annexe['xs:sequence']['xs:element']\n",
    "    list_records = []\n",
    "    dict_champs = dict()\n",
    "    nom_annexe = class_annexe[\"@name\"][1:]\n",
    "    \n",
    "    for element in elements:\n",
    "        documentation = element['xs:annotation']['xs:documentation']\n",
    "        if isinstance(documentation, str):\n",
    "            libelle = documentation\n",
    "            description = documentation\n",
    "        else:\n",
    "            libelle = element['xs:annotation']['xs:documentation']['z:libelle']\n",
    "            description = element['xs:annotation']['xs:documentation'].get('z:description')\n",
    "        dict_champs = {\n",
    "            \"nom_annexe\" : nom_annexe,\n",
    "            \"nom_champ\" : element[\"@name\"],\n",
    "            \"type\" : element[\"@type\"],\n",
    "            \"libelle\" : libelle,\n",
    "            \"description\" : description,\n",
    "        }\n",
    "        list_records.append(dict_champs)\n",
    "    \n",
    "    df = pd.DataFrame.from_records(list_records)\n",
    "    df[\"description\"] = df[\"description\"].str.replace(r'^<[^<>]*>', '', regex=True)\n",
    "    df[\"description\"] = df[\"description\"].str.replace(r'^\\s*<ul>', '', regex=True)\n",
    "    df[\"description\"] = df[\"description\"].str.replace(r'^\\s*<li>', '', regex=True)\n",
    "    df[\"description\"] = df[\"description\"].str.replace(r'<ul>', ' : ', regex=True)\n",
    "    df[\"description\"] = df[\"description\"].str.replace(r'<li>', ' - ', regex=True)\n",
    "    df[\"description\"] = df[\"description\"].str.replace(r'<[^<>]*>', ' ', regex=True)\n",
    "    df[\"description\"] = df[\"description\"].str.replace(r'\\s\\s+', ' ', regex=True)\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n",
    "def _merge_annexe_type_and_documentation(chemin_annexe: Path, complex_type_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    class_to_generate = create_dict_from_xml(chemin_annexe)['xs:schema']['xs:complexType'][1]\n",
    "    init_df = _parse_annexe_fields_documentation(class_to_generate)\n",
    "    init_df = init_df.merge(complex_type_df, how='left')\n",
    "    return init_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "PATH_TO_SCHEMA = Path(\"./download/\")\n",
    "\n",
    "def _get_list_annexes_path():\n",
    "    dict_annexe = create_dict_from_xml(PATH_TO_SCHEMA.joinpath(\"SchemaDocBudg/Class_Annexes.xsd\"))[\"xs:schema\"]['xs:include']\n",
    "    dict_annexe.pop(0)\n",
    "    class_annexe_paths = []\n",
    "    for annexe in dict_annexe: \n",
    "        class_annexe_paths.append(PATH_TO_SCHEMA.joinpath(f\"SchemaDocBudg/{annexe['@schemaLocation']}\"))\n",
    "    return class_annexe_paths\n",
    "\n",
    "\n",
    "def _parse_all_annexes_fields_documentation() -> pd.DataFrame:\n",
    "    #Erreurs à traiter manuellement :\n",
    "    # - l'annexe signatures dont la balise xs:complextype est inversée par rapport à l'habitude, il faut copier le premier bloc xs:complextype en dessous du 2ème.\n",
    "    # - l'annexe emprunt \"IndSousJacentDtVote\" ou il y a deux balises documentation qui génère une liste (seul cas)\n",
    "    df_result = pd.DataFrame()\n",
    "    \n",
    "    annexes_paths = _get_list_annexes_path()\n",
    "    annexe_complexe_types = _generate_complex_type_df(PATH_TO_SCHEMA.joinpath(\"SchemaDocBudg/CommunAnnexe.xsd\"))\n",
    "    \n",
    "    for annexe_path in annexes_paths:\n",
    "        df = _merge_annexe_type_and_documentation(annexe_path, annexe_complexe_types)\n",
    "        df_result = pd.concat([df, df_result])\n",
    "    \n",
    "    return df_result.set_index('nom_champ')\n",
    "\n",
    "\n",
    "def generate_annexe_data_documentation_csv(path_to_export : Path):\n",
    "    df_to_csv = _parse_all_annexes_fields_documentation()\n",
    "    generate_csv(path_to_export, df_to_csv)  \n",
    "    \n",
    "\n",
    "def generate_csv(path_to_export : Path, df_to_csv : pd.DataFrame):\n",
    "    df_to_csv.to_csv(path_to_export, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "def connection_pg2():\n",
    "    return psycopg2.connect(database =\"actes_budgetaire\", user = \"postgres\",\n",
    "                        password = \"vGXGLqTY4EF7DCiozYoKlqRRUaC7ECd\", host = \"ab-postgres\",\n",
    "                        port = \"5432\")\n",
    "\n",
    "def get_data(connexion, annexe, year, nature_dec):\n",
    "    query= f\"\"\"SELECT annexe.id as annexe_id, *  FROM annexe \n",
    "    JOIN documentbudgetaire \n",
    "        ON documentbudgetaire.id = annexe.fk_id_document_budgetaire\n",
    "    JOIN collectivite \n",
    "        ON collectivite.siret_coll = documentbudgetaire.fk_siret_collectivite \n",
    "    WHERE annexe.type_annexe = '{annexe}' \n",
    "    AND documentbudgetaire.exercice = '{year}'\n",
    "    AND documentbudgetaire.nature_dec = '{nature_dec}' \n",
    "    AND documentbudgetaire.fk_siret_collectivite = '21640260200017'\n",
    "    \"\"\"\n",
    "    dat = pd.read_sql_query(query, connexion)\n",
    "    return dat\n",
    "\n",
    "needed_columns = ['annexe_id', 'fk_id_document_budgetaire', 'exercice', 'type_annexe', 'json_annexe','siret_etablissement', 'libelle', 'nomenclature', 'nature_dec', 'nature_vote','type_budget', 'siret_coll', 'libelle_collectivite', 'nature_collectivite']\n",
    "\n",
    "def keep_needed_columns(needed_columns : list, df : pd.DataFrame) -> pd.DataFrame:\n",
    "    to_drop = [item for item in list(df.columns) if item not in needed_columns]\n",
    "    return df.drop(to_drop, axis=1)\n",
    "\n",
    "import app.backend.timer as timer\n",
    "import app.backend.config as conf\n",
    "\n",
    "data = conf.CHAMPS_ANNEXES\n",
    "    \n",
    "def annexe(nom):\n",
    "    donnees = data[nom]\n",
    "    return donnees\n",
    "\n",
    "EMPRUNT_FIELD = annexe(nom=\"DATA_EMPRUNT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - récupération des champs spéciaux\n",
    "#Quid des données obsolètes ?\n",
    "# A gérer le cas de CodMotifContrAgent (nested documentation)\n",
    "to_replace = _parse_all_annexes_fields_documentation()[\"enum\"]   \\\n",
    "                                        .dropna()  \\\n",
    "                                        .to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import copy\n",
    "\n",
    "def _all_annexe_columns(df, annexe_fields):\n",
    "    all_columns = copy.deepcopy(annexe_fields)\n",
    "    columns = list(df.columns)\n",
    "    for i in columns:\n",
    "        all_columns.append(i)\n",
    "    return all_columns\n",
    "\n",
    "@timer.timed\n",
    "def explode_annexe_json_into_rows_first_way(df, annexe_fields):\n",
    "    all_columns = _all_annexe_columns(df, annexe_fields)\n",
    "    df['json_annexe'] = df.json_annexe.apply(eval)\n",
    "    temp = df.groupby('annexe_id').json_annexe.apply(lambda x: pd.DataFrame(x.values[0])).reset_index()\n",
    "    df.drop(columns=\"json_annexe\", inplace=True)\n",
    "    df_result = temp.merge(df, left_on='annexe_id', right_on='annexe_id')\n",
    "    return result.reindex(columns = all_columns)\n",
    "  \n",
    "@timer.timed\n",
    "def explode_annexe_json_into_rows_second_way(df, annexe_fields):\n",
    "    all_columns = _all_annexe_columns(df, annexe_fields)\n",
    "    s= df.set_index('annexe_id').json_annexe.apply(eval).explode()\n",
    "    temp = pd.DataFrame(s.tolist(), index = s.index).reset_index()\n",
    "    df.drop(columns=\"json_annexe\", inplace=True)\n",
    "    df_result = temp.merge(df, left_on='annexe_id', right_on='annexe_id')\n",
    "    return result.reindex(columns = all_columns)\n",
    "\n",
    "@timer.timed\n",
    "def explode_annexe_json_into_rows_third_way_old(df, annexe_fields, path: Path, to_replace):\n",
    "    dfs = []\n",
    "    dict_annexe = dict()\n",
    "    for index, row  in df.iterrows():\n",
    "        dict_annexe[index] = json.loads(row[\"json_annexe\"])\n",
    "        for element in dict_annexe[index]:\n",
    "            if element:\n",
    "                for field in annexe_fields:\n",
    "                    element.setdefault(field, None)\n",
    "\n",
    "        json_df = pd.json_normalize(dict_annexe[index])\n",
    "        #dfs.append(json_df.assign(**row.drop(\"json_annexe\")))\n",
    "        df_temp = json_df.assign(**row.drop(\"json_annexe\"))#.replace(to_replace, inplace=True)\n",
    "        append_csv(df_temp, path)\n",
    "\n",
    "@timer.timed\n",
    "def explode_annexe_json_into_rows_third_way(df, annexe_fields, path: Path, to_replace, needed_columns):\n",
    "    dfs = []\n",
    "    dict_annexe = dict()\n",
    "    for index, row  in df.iterrows():\n",
    "        dict_annexe = json.loads(row[\"json_annexe\"])\n",
    "        for element in dict_annexe:\n",
    "            if element:\n",
    "                for field in annexe_fields:\n",
    "                    element.setdefault(field, None)\n",
    "\n",
    "        json_df = pd.json_normalize(dict_annexe)\n",
    "        #dfs.append(json_df.assign(**row.drop(\"json_annexe\")))\n",
    "        df_temp = json_df.assign(**row.drop(\"json_annexe\"))#.replace(to_replace, inplace=True)\n",
    "        try:\n",
    "            df_temp.replace(to_replace, inplace=True)\n",
    "        except TypeError:\n",
    "            print(df_temp[annexe_id])\n",
    "        if index == 0:\n",
    "            all_columns = needed_columns + annexe_fields\n",
    "            all_columns.remove(\"json_annexe\")\n",
    "            generate_csv(df_temp, path, all_columns)\n",
    "        else:\n",
    "            try:\n",
    "                append_csv(df_temp, path, all_columns)\n",
    "            except KeyError:\n",
    "                print(df_temp)\n",
    "\n",
    "def generate_csv(df, path: Path, annexe_fields):\n",
    "    return df.to_csv(path, mode='a', index=False, columns=annexe_fields, header=True)\n",
    "\n",
    "def append_csv(df, path: Path, annexe_fields):\n",
    "    return df.to_csv(path, mode='a', index=False, columns=annexe_fields, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()\n",
    "elements = os.listdir(Path(\"./csv/2020\"))\n",
    "elements = map(lambda e :  e.split(\".\")[0] , elements)\n",
    "elements = list(elements)\n",
    "annexes = list(data.keys())\n",
    "annexes_manquantes = [item for item in annexes if item not in elements]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annexe_id</th>\n",
       "      <th>id</th>\n",
       "      <th>type_annexe</th>\n",
       "      <th>json_annexe</th>\n",
       "      <th>fk_id_document_budgetaire</th>\n",
       "      <th>siret_etablissement</th>\n",
       "      <th>list_annexes</th>\n",
       "      <th>id</th>\n",
       "      <th>libelle</th>\n",
       "      <th>code_insee</th>\n",
       "      <th>...</th>\n",
       "      <th>num_dec</th>\n",
       "      <th>nature_vote</th>\n",
       "      <th>type_budget</th>\n",
       "      <th>id_etabl_princ</th>\n",
       "      <th>json_budget</th>\n",
       "      <th>fk_siret_collectivite</th>\n",
       "      <th>siret_coll</th>\n",
       "      <th>libelle_collectivite</th>\n",
       "      <th>nature_collectivite</th>\n",
       "      <th>departement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76910</td>\n",
       "      <td>76910</td>\n",
       "      <td>DATA_EMPRUNT</td>\n",
       "      <td>[{\"CodTypEmpr\": \"01\", \"CodProfilAmort\": \"X\", \"...</td>\n",
       "      <td>13473</td>\n",
       "      <td>21640260200017</td>\n",
       "      <td>[DATA_EMPRUNT, DATA_TRESORERIE, DATA_TIERS, DA...</td>\n",
       "      <td>13473</td>\n",
       "      <td>BUDGET PRINCIPAL</td>\n",
       "      <td>64260</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>P</td>\n",
       "      <td>None</td>\n",
       "      <td>[{\"Nature\": \"001\", \"Fonction\": \"01\", \"ContNat\"...</td>\n",
       "      <td>21640260200017</td>\n",
       "      <td>21640260200017</td>\n",
       "      <td>01 VILLE DE HENDAYE</td>\n",
       "      <td>COMMUNE dont la population est de 3500 habitan...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   annexe_id     id   type_annexe  \\\n",
       "0      76910  76910  DATA_EMPRUNT   \n",
       "\n",
       "                                         json_annexe  \\\n",
       "0  [{\"CodTypEmpr\": \"01\", \"CodProfilAmort\": \"X\", \"...   \n",
       "\n",
       "   fk_id_document_budgetaire siret_etablissement  \\\n",
       "0                      13473      21640260200017   \n",
       "\n",
       "                                        list_annexes     id           libelle  \\\n",
       "0  [DATA_EMPRUNT, DATA_TRESORERIE, DATA_TIERS, DA...  13473  BUDGET PRINCIPAL   \n",
       "\n",
       "  code_insee  ... num_dec  nature_vote type_budget id_etabl_princ  \\\n",
       "0      64260  ...    None            3           P           None   \n",
       "\n",
       "                                         json_budget fk_siret_collectivite  \\\n",
       "0  [{\"Nature\": \"001\", \"Fonction\": \"01\", \"ContNat\"...        21640260200017   \n",
       "\n",
       "       siret_coll libelle_collectivite  \\\n",
       "0  21640260200017  01 VILLE DE HENDAYE   \n",
       "\n",
       "                                 nature_collectivite departement  \n",
       "0  COMMUNE dont la population est de 3500 habitan...        None  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with connection_pg2() as conn:\n",
    "    dat = get_data(connexion=conn, annexe=\"DATA_EMPRUNT\", year=2020, nature_dec= '09')\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "2022-11-29 11:10:26,152 DEBUG -- explode_annexe_json_into_rows_third_way ran in 0.04s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_EMPRUNT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "2022-11-29 11:10:26,488 DEBUG -- explode_annexe_json_into_rows_third_way ran in 0.01s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_TRESORERIE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "2022-11-29 11:10:27,649 DEBUG -- explode_annexe_json_into_rows_third_way ran in 0.01s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_TIERS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "2022-11-29 11:10:28,857 DEBUG -- explode_annexe_json_into_rows_third_way ran in 0.02s\n",
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "2022-11-29 11:10:29,017 DEBUG -- explode_annexe_json_into_rows_third_way ran in 0.01s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_CONCOURS\n",
      "DATA_RECETTE_AFFECTEE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "2022-11-29 11:10:29,691 DEBUG -- explode_annexe_json_into_rows_third_way ran in 0.01s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_FORMATION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "2022-11-29 11:10:32,492 DEBUG -- explode_annexe_json_into_rows_third_way ran in 0.02s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_CONSOLIDATION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "2022-11-29 11:10:33,465 DEBUG -- explode_annexe_json_into_rows_third_way ran in 0.01s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_ORGANISME_GROUP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "2022-11-29 11:10:34,636 DEBUG -- explode_annexe_json_into_rows_third_way ran in 0.02s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_PATRIMOINE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "2022-11-29 11:10:35,431 DEBUG -- explode_annexe_json_into_rows_third_way ran in 0.04s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_PERSONNEL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "2022-11-29 11:10:36,297 DEBUG -- explode_annexe_json_into_rows_third_way ran in 0.02s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_VENTILATION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "2022-11-29 11:10:37,182 DEBUG -- explode_annexe_json_into_rows_third_way ran in 0.01s\n",
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "2022-11-29 11:10:37,351 DEBUG -- explode_annexe_json_into_rows_third_way ran in 0.01s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_AMORTISSEMENT_METHODE\n",
      "DATA_PROVISION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "2022-11-29 11:10:38,060 DEBUG -- explode_annexe_json_into_rows_third_way ran in 0.01s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_SIGNATURE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "2022-11-29 11:10:38,567 DEBUG -- explode_annexe_json_into_rows_third_way ran in 0.01s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_SIGNATAIRE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "2022-11-29 11:10:39,246 DEBUG -- explode_annexe_json_into_rows_third_way ran in 0.01s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_ETAB_SERVICE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "/home/admin/miniconda3/envs/dataprep/lib/python3.10/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "2022-11-29 11:10:40,133 DEBUG -- explode_annexe_json_into_rows_third_way ran in 0.02s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_SOMMAIRE\n"
     ]
    }
   ],
   "source": [
    "import app.backend.config as conf\n",
    "\n",
    "PATH_TO_EXPORT = Path(\"./csv/2020/hendaye\")\n",
    "                      \n",
    "needed_columns = ['annexe_id', 'fk_id_document_budgetaire', 'exercice', 'type_annexe', 'json_annexe','siret_etablissement', 'libelle', 'nomenclature', 'nature_dec', 'nature_vote','type_budget', 'siret_coll', 'libelle_collectivite', 'nature_collectivite']\n",
    "data = conf.CHAMPS_ANNEXES\n",
    "\n",
    "to_replace[\"nature_dec\"] = dict(zip([\"01\", \"02\", \"03\", \"09\"],\n",
    "              [\"Budget primitif\", \"Décision modificative\", \"Budget supplémentaire\", \"Compte administratif\"]))\n",
    "to_replace[\"type_budget\"] = dict(zip([\"P\", \"A\"],\n",
    "                      [\"Principal\",\"Annexe\"]))\n",
    "\n",
    "\n",
    "for annexe in data.keys():\n",
    "    with connection_pg2() as conn:\n",
    "        dat = get_data(connexion=conn, annexe=annexe, year=2020, nature_dec= '09')\n",
    "    df = keep_needed_columns(needed_columns, dat)\n",
    "    if not df.empty:\n",
    "        print(annexe)\n",
    "        try:\n",
    "            df_annexe = explode_annexe_json_into_rows_third_way(df,\n",
    "                                                data[annexe], \n",
    "                                                f\"{PATH_TO_EXPORT.joinpath(annexe)}.csv\",\n",
    "                                                to_replace,\n",
    "                                                needed_columns)\n",
    "            #df_annexe.replace(to_replace, inplace=True)\n",
    "            #generate_csv(f\"{PATH_TO_EXPORT.joinpath(annexe)}.csv\",df_annexe)\n",
    "        except NameError:\n",
    "            print(annexe)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "995cf7a9003b664b9db9fa0428cd4241a9dbfec89d188999a9a74ddf6e022b66"
  },
  "kernelspec": {
   "display_name": "Python (dataprep)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
